{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae799230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariaageikina/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932003b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the working directory\n",
    "main_path = os.getenv(\"DATA_PATH\")\n",
    "os.chdir(main_path + \"/carb_offsets/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f464545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load parcels\n",
    "parcels0 = gpd.read_file(\"build_forest_parcels/output/forest_parcels1km.gpkg\")\n",
    "parcels = parcels0.to_crs('EPSG:5070')\n",
    "parcels['parcel_id'] = parcels.index + 1\n",
    "parcels['parcel_area'] = parcels.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b954dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merge in wildfire hazard potential\n",
    "whp_path = 'build_fire_risk/input/raw/new_wildfire_hazard_potential/2014/RDS-2015-0047/Data/whp_2014_continuous/whp2014_cnt'\n",
    "stats = zonal_stats(parcels, whp_path, stats='mean', nodata=-2147483647)\n",
    "parcels['whp_2014'] = [stat['mean'] for stat in stats]\n",
    "parcels = parcels.dropna(subset=['whp_2014'])\n",
    "parcels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75d7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in conservation easement data\n",
    "CEs = gpd.read_file(\"build_conservation_easement/input/raw/NCED_08282020_shp\")\n",
    "CEs = CEs.to_crs(parcels.crs)\n",
    "CEs = CEs[CEs['owntype']!='FED']\n",
    "CEs = CEs[['unique_id','geometry']]\n",
    "\n",
    "CEs.rename(columns={'unique_id': 'ce_id'}, inplace=True)\n",
    "intersected = gpd.sjoin(parcels, CEs, how='left', predicate = 'intersects')\n",
    "\n",
    "intersected = intersected.groupby('parcel_id').agg({\n",
    "    'ce_id': lambda x: ', '.join(x.astype(str))\n",
    "}).reset_index()\n",
    "\n",
    "intersected['ce'] = 0\n",
    "intersected.loc[intersected['ce_id']!=\"nan\", 'ce'] = 1\n",
    "intersected[intersected['ce']==1]\n",
    "intersected = intersected[['parcel_id','ce']]\n",
    "\n",
    "parcels = parcels.merge(intersected, on='parcel_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3111d9b0-506f-4485-9db3-daf8de87ee4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariaageikina/anaconda3/lib/python3.11/site-packages/rasterstats/io.py:335: NodataWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#merge in canopy cover\n",
    "canopy_path14 = 'build_canopy_cover/input/raw/NLCD_2014/nlcd_tcc_conus_2014_v2021-4.tif'\n",
    "\n",
    "stats = zonal_stats(parcels, canopy_path14, stats='mean', nodata=None)\n",
    "parcels['canopy_2014'] = [stat['mean'] for stat in stats]\n",
    "parcels = parcels.dropna(subset=['canopy_2014'])\n",
    "parcels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc4b4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge in eco regions\n",
    "eco_region_gpds = []\n",
    "\n",
    "for region_num in range(1,11):\n",
    "        eco_region = gpd.read_file('build_eco_regions/input/raw/level4/reg'+str(region_num)+'_eco_l4')\n",
    "        eco_region = eco_region.to_crs('EPSG:5070')\n",
    "        \n",
    "        eco_region_gpds.append(eco_region)\n",
    " \n",
    "eco_regions = gpd.pd.concat(eco_region_gpds)\n",
    "\n",
    "eco_regions.drop(columns=['OBJECTID','L4_KEY','L3_KEY','L2_KEY','L1_KEY','Shape_Leng','Shape_Area'], inplace=True)\n",
    "\n",
    "intersected = gpd.overlay(parcels, eco_regions, how='intersection')\n",
    "intersected['intersect_area'] = intersected.geometry.area\n",
    "intersected = intersected[['parcel_id','US_L4CODE','US_L4NAME','US_L3CODE',\n",
    "                           'US_L3NAME','NA_L3CODE','NA_L3NAME','NA_L2CODE',\n",
    "                           'NA_L2NAME','NA_L1CODE','NA_L1NAME','STATE_NAME',\n",
    "                           'EPA_REGION','intersect_area']]\n",
    "\n",
    "aggregated_df = intersected.loc[\n",
    "    intersected.groupby(['parcel_id'])['intersect_area'].idxmax()\n",
    "]\n",
    "aggregated_df = aggregated_df.reset_index(drop=True)\n",
    "aggregated_df.drop(columns=['intersect_area'],inplace=True)\n",
    "\n",
    "parcels = parcels.merge(aggregated_df, on='parcel_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d09edba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/prztv6jj77l86gjc3j8qp4pr0000gn/T/ipykernel_5781/3700971061.py:6: UserWarning: `keep_geom_type=True` in overlay resulted in 5 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  intersected = gpd.overlay(parcels, projects, how='intersection')\n"
     ]
    }
   ],
   "source": [
    "#merge in projects\n",
    "projects = gpd.read_file(\"build_ARB/input/built/all_projects.gpkg\")\n",
    "projects = projects[projects.geometry.type.isin(['Polygon', 'MultiPolygon'])]\n",
    "projects = projects.to_crs(parcels.crs)\n",
    "\n",
    "intersected = gpd.overlay(parcels, projects, how='intersection')\n",
    "\n",
    "intersected_union = intersected.dissolve(by=\"parcel_id\", as_index=False)\n",
    "intersected_union['intersect_area'] = intersected.geometry.area\n",
    "intersected_union.drop(columns=[\"project\",\"type\"],inplace=True)\n",
    "\n",
    "intersected = intersected[['parcel_id','project','type']]\n",
    "\n",
    "intersected = intersected.groupby('parcel_id').agg({\n",
    "    'project': lambda x: ', '.join(x.astype(str)),\n",
    "    'type': lambda x: ', '.join(x.astype(str)),\n",
    "}).reset_index()\n",
    "intersected = intersected.merge(intersected_union[['parcel_id','intersect_area']])\n",
    "\n",
    "parcels = parcels.merge(intersected, on='parcel_id', how='left')\n",
    "parcels['intersect_area'] = parcels['intersect_area'].fillna(0)\n",
    "parcels['project_share'] = parcels['intersect_area'] / parcels['parcel_area']\n",
    "parcels.drop(columns=['intersect_area'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e362ae-20be-4ec9-9a9f-77a01dfacd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge in census tracts\n",
    "census_tracts = gpd.read_file(main_path+\"/wfs_media/data/build_wildfire_reports/input/raw/census_tracts/nhgis0001_shape/2014\")\n",
    "census_tracts = census_tracts.to_crs(parcels.crs)\n",
    "\n",
    "intersected = gpd.overlay(parcels, census_tracts[['GEOID','geometry']], how='intersection')\n",
    "intersected['intersect_area'] = intersected.geometry.area\n",
    "intersected = intersected[['parcel_id','GEOID','intersect_area']]\n",
    "\n",
    "aggregated_df = intersected.loc[\n",
    "    intersected.groupby(['parcel_id'])['intersect_area'].idxmax()\n",
    "]\n",
    "aggregated_df = aggregated_df.reset_index(drop=True)\n",
    "aggregated_df.drop(columns=['intersect_area'],inplace=True)\n",
    "\n",
    "parcels = parcels.merge(aggregated_df, on='parcel_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eb9a7ab-5c10-4ea6-9760-e553d0f5fdde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge in zipcodes\n",
    "zipcodes = gpd.read_file(main_path+\"/wfs_media/data/build_wildfire_reports/input/raw/zipcodes/USA_ZIP_Code_Boundaries.gpkg\")\n",
    "zipcodes = zipcodes[['ZIP_CODE','geometry']]\n",
    "\n",
    "intersected = gpd.overlay(parcels, zipcodes, how='intersection')\n",
    "intersected['intersect_area'] = intersected.geometry.area\n",
    "intersected = intersected[['parcel_id','ZIP_CODE','intersect_area']]\n",
    "\n",
    "aggregated_df = intersected.loc[\n",
    "    intersected.groupby(['parcel_id'])['intersect_area'].idxmax()\n",
    "]\n",
    "aggregated_df = aggregated_df.reset_index(drop=True)\n",
    "aggregated_df.drop(columns=['intersect_area'],inplace=True)\n",
    "\n",
    "parcels = parcels.merge(aggregated_df, on='parcel_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5fc0b4-b3db-4e6f-a2df-836748515435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge in counties\n",
    "counties = gpd.read_file(main_path+\"/wfs_media/data/build_wildfire_reports/input/raw/county_boundaries/gz_2010_us_050_00_20m\")\n",
    "counties = counties.to_crs(parcels.crs)\n",
    "counties.loc[:,'fips'] = (counties['STATE']+counties['COUNTY']).astype(int)\n",
    "counties\n",
    "\n",
    "intersected = gpd.overlay(parcels, counties, how='intersection')\n",
    "intersected['intersect_area'] = intersected.geometry.area\n",
    "intersected = intersected[['parcel_id','fips','intersect_area']]\n",
    "intersected\n",
    "\n",
    "aggregated_df = intersected.loc[\n",
    "    intersected.groupby(['parcel_id'])['intersect_area'].idxmax()\n",
    "]\n",
    "aggregated_df = aggregated_df.reset_index(drop=True)\n",
    "aggregated_df.drop(columns=['intersect_area'],inplace=True)\n",
    "\n",
    "parcels = parcels.merge(aggregated_df, on='parcel_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3fc0ec-a2c0-4366-9d40-5b11b3de7e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge in housing prices\n",
    "housing = pd.read_csv(\"build_housing/input/raw/Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\")\n",
    "housing['housing_value2014'] = housing.filter(regex='^2014').mean(axis=1, skipna=True)\n",
    "housing = housing[['RegionName','housing_value2014']]\n",
    "housing.rename(columns={\"RegionName\":\"ZIP_CODE\"}, inplace=True)\n",
    "housing['ZIP_CODE'] = housing['ZIP_CODE'].astype(str)\n",
    "\n",
    "parcels = parcels.merge(housing,how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d50fe427-5e15-4038-aad0-07712966b763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/prztv6jj77l86gjc3j8qp4pr0000gn/T/ipykernel_5781/2946491850.py:2: DtypeWarning: Columns (2,3,4,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,38,39,40,42,43,46,47,50,51,54,55,56,58,59,62,63,64,66,67,70,71,72,74,75,78,79,82,83,86,87,90,91,94,95,102,103,104,106,107,110,111,114,115,118,119,122,123,126,127,128,130,131,134,135,138,139,142,143,146,147,150,151,154,155,158,159,162,163,166,167,170,171,174,175,178,179,182,183,184,186,187,190,191,194,195,198,199,202,203,204,206,207,210,211,214,215,218,219,222,223,226,227,230,231,234,235,238,239,242,243,254,255,262,263,270,271,278,279,286,287,294,295,298,299,300,302,303,306,307,310,311,314,315,318,319,322,323,326,327,330,331,334,335,338,339,354,355,356,378,379,380,382,383,386,387,390,391,394,395,398,399,400,402,403,406,407,408,410,411,412,414,415,416,418,419,422,423,426,427,430,431,434,435,436,438,439,442,443,446,447,450,451,454,455,456,458,459,462,463,466,467,470,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  census = pd.read_csv('build_socioeconomic/input/raw/ACSDP5Y2014/ACSDP5Y2014.DP03-Data.csv')\n",
      "/var/folders/bm/prztv6jj77l86gjc3j8qp4pr0000gn/T/ipykernel_5781/2946491850.py:3: DtypeWarning: Columns (2,3,10,11,18,19,26,27,34,35,42,43,50,51,58,59,66,67,74,75,82,83,90,91,98,99,106,107,114,115,122,123,130,131,138,139,146,147,154,155,162,163,170,171,178,179,186,187,194,195,202,203,210,211,218,219,226,227) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  census2 = pd.read_csv('build_socioeconomic/input/raw/ACSST5Y2014/ACSST5Y2014.S2301-Data.csv')\n"
     ]
    }
   ],
   "source": [
    "#merge in census data\n",
    "census = pd.read_csv('build_socioeconomic/input/raw/ACSDP5Y2014/ACSDP5Y2014.DP03-Data.csv')\n",
    "census2 = pd.read_csv('build_socioeconomic/input/raw/ACSST5Y2014/ACSST5Y2014.S2301-Data.csv')\n",
    "\n",
    "census = census.merge(census2)\n",
    "\n",
    "census = census[['GEO_ID','DP03_0030E','DP03_0030PE','DP03_0033E','DP03_0033PE','DP03_0051E',\n",
    "                'S2301_C01_001E','S2301_C04_001E','S2301_C01_023E','S2301_C01_026E',\n",
    "                   'S2301_C01_029E','S2301_C01_019E']]\n",
    "\n",
    "census = census.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "census.replace(\"-\", np.nan, inplace=True)\n",
    "census.loc[:, census.columns != 'GEO_ID'] = census.loc[:, census.columns != 'GEO_ID'].astype(float)\n",
    "\n",
    "for col in census.columns:\n",
    "    if col!=\"GEO_ID\":\n",
    "        census[col] = pd.to_numeric(census[col], errors='coerce')\n",
    "\n",
    "census['GEOID'] = census['GEO_ID'].str[9:]\n",
    "census['poverty_rate'] = np.where((census['S2301_C01_001E'] != 0) & (~census['S2301_C01_001E'].isna()),\n",
    "                                  census['S2301_C01_023E'] / census['S2301_C01_001E'],\n",
    "                                  np.nan)\n",
    "census['nohighschool_rate'] = np.where((census['S2301_C01_019E'] != 0) & (~census['S2301_C01_019E'].isna()),\n",
    "                                  census['S2301_C01_026E'] / census['S2301_C01_019E'],\n",
    "                                  np.nan)\n",
    "census['collegegrads_rate'] = np.where((census['S2301_C01_019E'] != 0) & (~census['S2301_C01_019E'].isna()),\n",
    "                                  census['S2301_C01_029E'] / census['S2301_C01_019E'],\n",
    "                                  np.nan)\n",
    "\n",
    "census.drop(columns=['GEO_ID','S2301_C01_023E','S2301_C01_026E','S2301_C01_029E'],inplace=True)\n",
    "census.rename(columns={\"DP03_0030E\":\"jobs1\",\"DP03_0030PE\":\"jobs1_p\",\"DP03_0033E\":\"jobs2\",\n",
    "                      \"DP03_0033PE\":\"jobs2_p\",\"DP03_0051E\":\"income\",\"S2301_C01_001E\":\"pop16plus\",\n",
    "                       \"S2301_C04_001E\":\"unemp_rate\",\"S2301_C01_019E\":\"pop20_64\"}, inplace=True)\n",
    "\n",
    "parcels = parcels.merge(census,how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15c52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export all data\n",
    "parcels.to_file('merge_data/output/merged_carb.gpkg', layer='alldata', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
